import requests
import re
import base64
import subprocess
import concurrent.futures

# è®¢é˜…é“¾æ¥åˆ—è¡¨ï¼ˆæ”¯æŒå¤šä¸ªé“¾æ¥ï¼‰
SUBSCRIBE_URLS = [
    "https://example.com/subscription1",
    "https://example.com/subscription2"
]

# è·å–èŠ‚ç‚¹ï¼ˆæ”¯æŒå¤šä¸ªé“¾æ¥ï¼‰
def fetch_nodes():
    nodes = []
    for url in SUBSCRIBE_URLS:
        try:
            print(f"ğŸŒ è·å–è®¢é˜…: {url}")
            response = requests.get(url)
            if response.status_code != 200:
                print(f"âŒ æ— æ³•è·å– {url}ï¼ŒçŠ¶æ€ç : {response.status_code}")
                continue
            decoded = base64.b64decode(response.content).decode('utf-8')
            fetched_nodes = decoded.strip().split('\n')
            print(f"ğŸ§ª è§£ç åèŠ‚ç‚¹å†…å®¹:\n{decoded}")  # â¡ï¸ æ‰“å°è§£ç åçš„å†…å®¹
            nodes.extend(fetched_nodes)
            print(f"âœ… ä» {url} è·å–åˆ° {len(fetched_nodes)} ä¸ªèŠ‚ç‚¹")
        except Exception as e:
            print(f"âŒ è·å– {url} å¤±è´¥: {e}")
    return nodes

# å»é‡
def deduplicate(nodes):
    return list(set(nodes))

# æµ‹é€Ÿï¼ˆè¿”å›å»¶è¿Ÿæ—¶é—´ï¼‰
def test_node(node):
    host = extract_host(node)
    if not host:
        print(f"â“ æœªèƒ½æå–ä¸»æœºå: {node}")
        return None
    
    try:
        print(f"ğŸš€ æµ‹é€Ÿ {host} ...")
        # å°è¯•ä½¿ç”¨ ping æµ‹é€Ÿ
        result = subprocess.run(
            ["ping", "-c", "3", "-W", "2", host],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        print(f"ğŸ§ª Ping å®Œæ•´ç»“æœ:\n{result.stdout}")  # â¡ï¸ æ‰“å°å®Œæ•´çš„ ping è¾“å‡º
        if result.returncode == 0:
            match = re.search(r"min/avg/max/mdev = ([\d.]+)/", result.stdout)
            if match:
                latency = float(match.group(1))
                print(f"âœ… åŒ¹é…åˆ°å»¶è¿Ÿå€¼: {latency} ms")
                return (node, latency)
            else:
                print("âŒ æ­£åˆ™åŒ¹é…å¤±è´¥ï¼å¯èƒ½æ˜¯ ping è¾“å‡ºæ ¼å¼ä¸åŒã€‚")
        else:
            print(f"âŒ Ping æµ‹é€Ÿå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
        
        # å¦‚æœ ping å¤±è´¥ï¼Œæ”¹ç”¨ curl æµ‹é€Ÿ
        result = subprocess.run(
            ["curl", "-o", "/dev/null", "-s", "-w", "%{time_connect}", f"http://{host}"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        if result.returncode == 0:
            latency = float(result.stdout.strip()) * 1000  # å•ä½è½¬æ¢ä¸º ms
            print(f"âœ… ä½¿ç”¨ curl æµ‹é€Ÿ: {host} - {latency:.2f} ms")
            return (node, latency)
        else:
            print(f"âŒ curl æµ‹é€Ÿå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
    except Exception as e:
        print(f"âŒ {host} - æµ‹é€Ÿå¤±è´¥: {e}")
    
    return None

# ä»èŠ‚ç‚¹URLæå–ä¸»æœºå
def extract_host(node):
    match = re.search(r'@(.*?):', node)
    if match:
        return match.group(1)
    return None

# å¤„ç†èŠ‚ç‚¹
def process_nodes():
    nodes = fetch_nodes()
    print(f"ğŸ’¡ è·å–åˆ°æ€»å…± {len(nodes)} ä¸ªèŠ‚ç‚¹")

    nodes = deduplicate(nodes)
    print(f"ğŸ—‘ï¸ å»é‡åå‰©ä½™ {len(nodes)} ä¸ªèŠ‚ç‚¹")

    valid_nodes = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        results = executor.map(test_node, nodes)
        for result in results:
            if result:
                valid_nodes.append(result)

    # æŒ‰å»¶è¿Ÿæ’åºï¼Œå–å‰5ä¸ª
    valid_nodes = sorted(valid_nodes, key=lambda x: x[1])[:5]
    print(f"ğŸš€ ä¿ç•™æœ€å¿«çš„ {len(valid_nodes)} ä¸ªèŠ‚ç‚¹")

    # è¾“å‡ºåˆ° result.txt
    if not valid_nodes:
        print("âš ï¸ æœªè·å–åˆ°æœ‰æ•ˆèŠ‚ç‚¹ï¼Œè¾“å‡ºä¸ºç©ºï¼")
    else:
        with open("result.txt", "w") as f:
            for node, latency in valid_nodes:
                f.write(f"{node} # {latency}ms\n")
                print(f"ğŸ“ è¾“å‡ºåˆ°æ–‡ä»¶: {node} - {latency}ms")  # âœ… è°ƒè¯•è¾“å‡º
        print("ğŸ¯ å·²ä¿å­˜åˆ° result.txt")

if __name__ == "__main__":
    process_nodes()
