import requests
import re
import base64
import subprocess
import concurrent.futures

# è®¢é˜…é“¾æ¥åˆ—è¡¨ï¼ˆæ”¯æŒå¤šä¸ªé“¾æ¥ï¼‰
SUBSCRIBE_URLS = [
    "https://raw.githubusercontent.com/xiaomayi0804/ding/refs/heads/main/vip-jd",
    "https://raw.githubusercontent.com/xiaomayi0804/ding/refs/heads/main/vip-jd2"
    "https://raw.githubusercontent.com/xiaomayi0804/ding/refs/heads/main/vip-jd1"
]

# è·å–èŠ‚ç‚¹ï¼ˆæ”¯æŒå¤šä¸ªé“¾æ¥ï¼‰
def fetch_nodes():
    nodes = []
    for url in SUBSCRIBE_URLS:
        try:
            print(f"ğŸŒ è·å–è®¢é˜…: {url}")
            response = requests.get(url)
            if response.status_code != 200:
                print(f"âŒ æ— æ³•è·å– {url}ï¼ŒçŠ¶æ€ç : {response.status_code}")
                continue
            decoded = base64.b64decode(response.content).decode('utf-8')
            fetched_nodes = decoded.strip().split('\n')
            nodes.extend(fetched_nodes)
            print(f"âœ… ä» {url} è·å–åˆ° {len(fetched_nodes)} ä¸ªèŠ‚ç‚¹")
        except Exception as e:
            print(f"âŒ è·å– {url} å¤±è´¥: {e}")
    return nodes

# å»é‡
def deduplicate(nodes):
    return list(set(nodes))

# æµ‹é€Ÿï¼ˆè¿”å›å»¶è¿Ÿæ—¶é—´ï¼‰
def test_node(node):
    host = extract_host(node)
    if not host:
        return None
    
    try:
        # ç”¨ ping æµ‹é€Ÿ
        result = subprocess.run(
            ["ping", "-c", "3", "-W", "2", host],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        if result.returncode == 0:
            # æå–å»¶è¿Ÿï¼ˆå–pingæœ€å°å€¼ï¼‰
            match = re.search(r"min/avg/max/mdev = ([\d.]+)/", result.stdout)
            if match:
                latency = float(match.group(1))
                print(f"âœ… {host} - {latency} ms")
                return (node, latency)
    except Exception as e:
        print(f"âŒ {host} - æµ‹é€Ÿå¤±è´¥: {e}")
    
    return None

# ä»èŠ‚ç‚¹URLæå–ä¸»æœºå
def extract_host(node):
    match = re.search(r'@(.*?):', node)
    if match:
        return match.group(1)
    return None

# å¤„ç†èŠ‚ç‚¹
def process_nodes():
    nodes = fetch_nodes()
    print(f"ğŸ’¡ è·å–åˆ°æ€»å…± {len(nodes)} ä¸ªèŠ‚ç‚¹")

    nodes = deduplicate(nodes)
    print(f"ğŸ—‘ï¸ å»é‡åå‰©ä½™ {len(nodes)} ä¸ªèŠ‚ç‚¹")

    valid_nodes = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        results = executor.map(test_node, nodes)
        for result in results:
            if result:
                valid_nodes.append(result)

    # æŒ‰å»¶è¿Ÿæ’åºï¼Œå–å‰5ä¸ª
    valid_nodes = sorted(valid_nodes, key=lambda x: x[1])[:5]
    print(f"ğŸš€ ä¿ç•™æœ€å¿«çš„ {len(valid_nodes)} ä¸ªèŠ‚ç‚¹")

    # ä¿å­˜åˆ°æ ¹ç›®å½•çš„ result.txt æ–‡ä»¶
    with open("result.txt", "w") as f:
        for node, latency in valid_nodes:
            f.write(f"{node} # {latency}ms\n")

    print("ğŸ‰ èŠ‚ç‚¹å·²ä¿å­˜åˆ° result.txt")

if __name__ == "__main__":
    process_nodes()
